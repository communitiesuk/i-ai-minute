import logging
from typing import Any, TypeVar, cast

from openai import AsyncAzureOpenAI
from openai.types.chat import ChatCompletion, ChatCompletionMessageParam
from openai.types.chat.chat_completion import Choice

from common.settings import get_settings

from .base import ModelAdapter

settings = get_settings()
T = TypeVar("T")
logger = logging.getLogger(__name__)


class OpenAIModelAdapter(ModelAdapter):
    def __init__(
        self,
        model: str,
        api_key: str,
        azure_endpoint: str,
        azure_deployment: str,
        api_version: str = "2024-10-21",
        **kwargs: Any,

    ) -> None:

        self._model = model
        
 
        if not azure_endpoint:
            raise ValueError("Azure Endpoint is required for Azure OpenAI")
        if not azure_deployment:
            raise ValueError("Azure Deployment name is required for Azure OpenAI")
    
        arguments_for_client = {
            "api_key": api_key,
            "api_version": api_version,
        }


        endpoint = azure_endpoint.rstrip("/")
        base_url = f"{endpoint}/endpoint/deployments/{azure_deployment}"
        self.async_azure_client = AsyncAzureOpenAI(
            base_url=base_url,
            api_version=api_version,
            api_key=api_key,
        )   
        self._kwargs = kwargs

    async def structured_chat(self, messages: list[dict[str, str]], response_format: type[T]) -> T:
        response = await self.async_azure_client.beta.chat.completions.parse(
            model=self._model,
            messages=cast(list[ChatCompletionMessageParam], messages),
            response_format=response_format,
            **self._kwargs,
        )
        parsed = response.choices[0].message.parsed
        if parsed is None:
            msg = "OpenAI response.parsed is None"
            raise ValueError(msg)
        return cast(T, parsed)

    async def chat(self, messages: list[dict[str, str]]) -> str:
        response = await self.async_azure_client.chat.completions.create(
            model=self._model,
            messages=cast(list[ChatCompletionMessageParam], messages),
            temperature=0.0,
            max_tokens=16384,
        )
        choice = response.choices[0]
        self.choice_incomplete(choice, response)
        message_content = choice.message.content
        if message_content is None:
            msg = "OpenAI response.content is None"
            raise ValueError(msg)
        return message_content

    @staticmethod
    def choice_incomplete(choice: Choice, response: ChatCompletion) -> bool:
        if choice.finish_reason == "length":
            logger.warning(
                "max output tokens reached: ID: %s prompt_tokens: %s completion_tokens %s",
                response.id,
                response.usage.prompt_tokens if response.usage else None,
                response.usage.completion_tokens if response.usage else None,
            )
            return True
        return False
